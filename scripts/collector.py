"""
Gemini APIã®æ¤œç´¢æ©Ÿèƒ½ã‚’ä½¿ã£ã¦æœ€æ–°ã®AI/MLãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’é›†ã‚ã‚‹
"""
import json
import os
import sys
import re
from datetime import datetime
import time
import requests

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from google import genai
    from google.genai import types
except ImportError:
    print("ã‚¨ãƒ©ãƒ¼: google-genaiãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    print("pip install google-genai ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
    sys.exit(1)

try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    print("è­¦å‘Š: python-dotenvãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆç’°å¢ƒå¤‰æ•°ã®è‡ªå‹•èª­ã¿è¾¼ã¿ãŒç„¡åŠ¹ï¼‰")


def resolve_redirect_url(url, timeout=15, max_retries=2):
    """ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆURLã‚’å®Ÿéš›ã®ã‚½ãƒ¼ã‚¹URLã«è§£æ±ºã™ã‚‹"""
    if not url or not url.startswith('http'):
        return url
    
    # Google Vertex AIã®ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆURLã®å ´åˆã®ã¿è§£æ±º
    if 'vertexaisearch.cloud.google.com/grounding-api-redirect' not in url:
        return url
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    
    for attempt in range(max_retries):
        try:
            # GETãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆå…ˆã‚’å–å¾—
            response = requests.get(
                url, 
                allow_redirects=True, 
                timeout=timeout, 
                headers=headers,
                stream=True
            )
            resolved_url = response.url
            
            # ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆãŒæˆåŠŸã—ãŸå ´åˆ
            if resolved_url and 'vertexaisearch.cloud.google.com' not in resolved_url:
                return resolved_url
                
        except requests.exceptions.RequestException as e:
            if attempt < max_retries - 1:
                time.sleep(1)  # ãƒªãƒˆãƒ©ã‚¤å‰ã«å¾…æ©Ÿ
                continue
            # æœ€çµ‚è©¦è¡Œã§å¤±æ•—
            pass
    
    return url  # å¤±æ•—æ™‚ã¯å…ƒã®URLã‚’è¿”ã™


def parse_markdown_to_news_items(markdown_text):
    """Markdownå½¢å¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æã—ã¦ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›"""
    news_items = []
    
    if not markdown_text:
        print("âš ï¸ ç©ºã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ä¿¡")
        return news_items
    
    try:
        # ãƒ‘ã‚¿ãƒ¼ãƒ³1: - [ã‚¿ã‚¤ãƒˆãƒ«](URL): è¦ç´„
        pattern1 = r'- \[([^\]]+)\]\(([^)]+)\):\s*(.+?)(?=\n- |\n\n|$)'
        matches = re.findall(pattern1, markdown_text, re.MULTILINE | re.DOTALL)
        
        for title, url, summary in matches:
            if url.strip().startswith('http'):
                news_items.append({
                    "title": title.strip(),
                    "summary": summary.strip()[:500],
                    "url": url.strip(),
                    "collected_at": datetime.now().isoformat()
                })
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³2: **ç•ªå·. ã‚¿ã‚¤ãƒˆãƒ«**\n[URL](URL): è¦ç´„ å½¢å¼ï¼ˆGeminiã®ä¸»è¦å‡ºåŠ›å½¢å¼ï¼‰
        if not news_items:
            pattern2 = r'\*\*\d+\.\s*([^*]+)\*\*\s*\n?\[?(https?://[^\s\)\]\n]+)\]?(?:\([^)]*\))?[:\s]*([^\n*]+)'
            matches = re.findall(pattern2, markdown_text, re.MULTILINE)
            for title, url, summary in matches:
                news_items.append({
                    "title": title.strip(),
                    "summary": summary.strip()[:500],
                    "url": url.strip(),
                    "collected_at": datetime.now().isoformat()
                })
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³3: ç•ªå·ä»˜ããƒªã‚¹ãƒˆ 1. [ã‚¿ã‚¤ãƒˆãƒ«](URL): è¦ç´„
        if not news_items:
            pattern3 = r'\d+\.\s*\[([^\]]+)\]\(([^)]+)\)[:\s]+(.+?)(?=\n\d+\.|\n\n|$)'
            matches = re.findall(pattern3, markdown_text, re.MULTILINE | re.DOTALL)
            for title, url, summary in matches:
                if url.strip().startswith('http'):
                    news_items.append({
                        "title": title.strip(),
                        "summary": summary.strip()[:500],
                        "url": url.strip(),
                        "collected_at": datetime.now().isoformat()
                    })
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³4: è¡Œã”ã¨ã«URLã‚’æ¢ã™ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        if not news_items:
            print("ğŸ“ æ¨™æº–ãƒ‘ã‚¿ãƒ¼ãƒ³ã§è§£æå¤±æ•—ã€è¡Œã”ã¨ã®è§£æã‚’è©¦è¡Œ...")
            lines = markdown_text.split('\n')
            current_title = None
            
            for i, line in enumerate(lines):
                line = line.strip()
                if not line:
                    continue
                
                # **ã‚¿ã‚¤ãƒˆãƒ«** ã‚’æ¤œå‡ºã—ã¦ä¿æŒ
                bold_match = re.search(r'\*\*\d*\.?\s*([^*]+)\*\*', line)
                if bold_match and 'http' not in line:
                    current_title = bold_match.group(1).strip()
                    continue
                
                # URLã‚’å«ã‚€è¡Œã‚’æ¤œå‡º
                url_match = re.search(r'https?://[^\s\)\]>\n]+', line)
                if url_match:
                    url = url_match.group(0).rstrip('.,;:')
                    
                    # ã‚¿ã‚¤ãƒˆãƒ«ã‚’æ±ºå®š
                    title = None
                    # [ã‚¿ã‚¤ãƒˆãƒ«] å½¢å¼ã‚’æ¢ã™
                    title_match = re.search(r'\[([^\]]+)\]', line)
                    if title_match:
                        title = title_match.group(1)
                    elif current_title:
                        title = current_title
                    else:
                        # è¡Œã®æœ€åˆã®éƒ¨åˆ†ã‚’ã‚¿ã‚¤ãƒˆãƒ«ã¨ã—ã¦ä½¿ç”¨
                        title = re.sub(r'https?://[^\s]+', '', line).strip()[:100]
                    
                    # è¦ç´„ã‚’æŠ½å‡º
                    summary_match = re.search(r'[:\-]\s*(.+)$', line)
                    summary = summary_match.group(1) if summary_match else ""
                    
                    if title and url and url.startswith('http'):
                        news_items.append({
                            "title": title[:200],
                            "summary": summary[:500],
                            "url": url,
                            "collected_at": datetime.now().isoformat()
                        })
                    
                    current_title = None  # ãƒªã‚»ãƒƒãƒˆ
        
        print(f"ğŸ“Š è§£æçµæœ: {len(news_items)}ä»¶ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ¤œå‡º")
        
        # é‡è¤‡URLã‚’é™¤å»
        seen_urls = set()
        unique_items = []
        for item in news_items:
            if item["url"] not in seen_urls:
                seen_urls.add(item["url"])
                unique_items.append(item)
        news_items = unique_items
        
        # ãã‚Œã§ã‚‚è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€å…¨ä½“ã‚’1ã¤ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¨ã—ã¦æ‰±ã†
        if not news_items:
            print("âš ï¸ ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è§£æã§ãã¾ã›ã‚“ã§ã—ãŸï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰")
            news_items.append({
                "title": "AI/ML News Collection",
                "summary": markdown_text[:500],
                "url": "",
                "collected_at": datetime.now().isoformat()
            })
            
    except Exception as e:
        print(f"âš ï¸ Markdownè§£æã‚¨ãƒ©ãƒ¼: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…¨ä½“ã‚’1ã¤ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¨ã—ã¦æ‰±ã†
        news_items.append({
            "title": "AI/ML News Collection",
            "summary": markdown_text[:500],
            "url": "",
            "collected_at": datetime.now().isoformat()
        })
    
    return news_items


def collect_news(max_retries=3):
    """Gemini APIã®æ¤œç´¢æ©Ÿèƒ½ã‚’ä½¿ã£ã¦ã€æœ€æ–°ã®AIãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åé›†ã™ã‚‹"""
    api_key = os.getenv("GEMINI_API_KEY")
    
    if not api_key:
        print("ã‚¨ãƒ©ãƒ¼: GEMINI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return None
    
    try:
        client = genai.Client(api_key=api_key)
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: Gemini APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None
    
    # Gemini 2.5 Flash Lite ã‚’ä½¿ç”¨ï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†ç”¨ï¼‰
    # è»½é‡ç‰ˆã§ã‚¯ã‚©ãƒ¼ã‚¿ã«ä½™è£•ãŒã‚ã‚‹
    model_name = 'gemini-2.5-flash-lite'
    
    # ä»Šæ—¥ã®æ—¥ä»˜ã‚’å–å¾—
    today = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
    
    # ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†æŒ‡ç¤ºãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢å‘ã‘ã€ä¿¡é ¼æ€§ã®é«˜ã„ã‚½ãƒ¼ã‚¹æŒ‡å®šï¼‰
    prompt = f"""ã‚ãªãŸã¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢å‘ã‘AIæŠ€è¡“ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚
ä»Šæ—¥ã¯{today}ã§ã™ã€‚

ã€å¯¾è±¡èª­è€…ã€‘
ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã€é–‹ç™ºè€…ã€MLã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢

ã€åé›†ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ç¨®é¡ã€‘ï¼ˆå„ªå…ˆåº¦é †ï¼‰
1. æ–°ã—ã„AIãƒ¢ãƒ‡ãƒ«ã®ãƒªãƒªãƒ¼ã‚¹ï¼ˆGPTã€Claudeã€Geminiã€Llamaã€Mistralãªã©ï¼‰
2. AIé–‹ç™ºãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆï¼ˆLangChainã€Hugging Faceã€vLLMãªã©ï¼‰
3. APIã®æ–°æ©Ÿèƒ½ãƒ»å¤‰æ›´ï¼ˆOpenAI APIã€Anthropic APIã€Google AI APIãªã©ï¼‰
4. AIé–¢é€£ã®OSSã®é‡è¦ãƒªãƒªãƒ¼ã‚¹ï¼ˆGitHubï¼‰
5. é–‹ç™ºè€…å‘ã‘AIã‚µãƒ¼ãƒ“ã‚¹ã®ç™ºè¡¨

ã€å¿…é ˆã‚½ãƒ¼ã‚¹ã€‘ä»¥ä¸‹ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã‹ã‚‰ã®ã¿é¸å®šï¼š
- openai.com, anthropic.com, blog.google, ai.meta.com
- techcrunch.com, theverge.com, venturebeat.com, arstechnica.com
- huggingface.co, github.blog, github.com/releases
- itmedia.co.jp, watch.impress.co.jp, gigazine.net

ã€é™¤å¤–ã€‘
- é›»åŠ›ã€åŒ»ç™‚ã€é‡‘èãªã©ã®æ¥­ç•Œç‰¹åŒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢å‘ã‘ã§ãªã„ã‚‚ã®ï¼‰
- è¦åˆ¶ãƒ»æ”¿ç­–ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆæŠ€è¡“çš„ã§ãªã„ã‚‚ã®ï¼‰
- å€‹äººãƒ–ãƒ­ã‚°ã€noteã€Qiitaã€ã¾ã¨ã‚ã‚µã‚¤ãƒˆ
- AIä¼æ¥­ã®è³‡é‡‘èª¿é”ãƒ»è²·åãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆæŠ€è¡“ç™ºè¡¨ã‚’é™¤ãï¼‰

ã€å‡ºåŠ›å½¢å¼ã€‘å³å¯†ã«ä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„:
- [ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ã‚¿ã‚¤ãƒˆãƒ«](å®Ÿéš›ã®URL): è¦ç´„ï¼ˆ50å­—ä»¥å†…ï¼‰

ä¾‹:
- [Claude 3.5 SonnetãŒãƒªãƒªãƒ¼ã‚¹](https://anthropic.com/news/claude-3-5): æ¨è«–èƒ½åŠ›ãŒå¤§å¹…ã«å‘ä¸Šã—ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã§æœ€é«˜æ€§èƒ½ã‚’é”æˆ

ã€å¿…é ˆæ¡ä»¶ã€‘
- å„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯2025å¹´12æœˆã®ã‚‚ã®ã§ã‚ã‚‹ã“ã¨
- URLã¯å¿…ãš https:// ã§å§‹ã¾ã‚‹å®Ÿéš›ã®URLã§ã‚ã‚‹ã“ã¨
- 5ä»¶é¸å®šã™ã‚‹ã“ã¨
- ä½™è¨ˆãªèª¬æ˜ã¯ä¸è¦ã€ä¸Šè¨˜å½¢å¼ã®ãƒªã‚¹ãƒˆã®ã¿å‡ºåŠ›"""
    
    for attempt in range(max_retries):
        try:
            # Google Search Groundingã‚’æœ‰åŠ¹åŒ–ã—ã¦å®Ÿéš›ã®Webæ¤œç´¢çµæœã‚’å–å¾—
            grounding_tool = types.Tool(
                google_search=types.GoogleSearch()
            )
            config = types.GenerateContentConfig(
                tools=[grounding_tool],
                temperature=0.3  # ä½ã‚ã«ã—ã¦äº‹å®Ÿé‡è¦–
            )
            
            response = client.models.generate_content(
                model=model_name,
                contents=[prompt],
                config=config
            )
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯Markdownå½¢å¼ã®ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦å–å¾—
            markdown_text = response.text
            
            # ãƒ‡ãƒãƒƒã‚°: ãƒ¬ã‚¹ãƒãƒ³ã‚¹å†…å®¹ã‚’å‡ºåŠ›ï¼ˆGitHub Actionsç”¨ï¼‰
            print("=" * 50)
            print("ğŸ“ Gemini APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ (å…ˆé ­1000æ–‡å­—):")
            print(markdown_text[:1000] if markdown_text else "(ç©º)")
            print("=" * 50)
            
            # Markdownã‚’JSONå½¢å¼ã«å¤‰æ›
            news_items = parse_markdown_to_news_items(markdown_text)
            
            # ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆURLã‚’å®Ÿéš›ã®ã‚½ãƒ¼ã‚¹URLã«è§£æ±º
            print("ğŸ”— URLã‚’è§£æ±ºä¸­...")
            for i, item in enumerate(news_items):
                original_url = item.get("url", "")
                if 'vertexaisearch.cloud.google.com' in original_url:
                    resolved_url = resolve_redirect_url(original_url)
                    if resolved_url != original_url:
                        print(f"  âœ… [{i+1}] {resolved_url[:60]}...")
                        item["url"] = resolved_url
                    else:
                        print(f"  âš ï¸ [{i+1}] URLè§£æ±ºã§ããšï¼ˆå…ƒã®URLã‚’ä½¿ç”¨ï¼‰")
            
            # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆanalyst.pyãŒèª­ã¿è¾¼ã‚€å½¢å¼ï¼‰
            output_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "news_raw.json")
            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(news_items, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†å®Œäº†: {len(news_items)}ä»¶")
            return news_items
            
        except Exception as e:
            wait_time = 2 ** attempt  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
            print(f"âš ï¸ APIã‚¨ãƒ©ãƒ¼ (è©¦è¡Œ {attempt + 1}/{max_retries}): {e}")
            if attempt < max_retries - 1:
                print(f"   {wait_time}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™...")
                time.sleep(wait_time)
            else:
                print("âŒ æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã«é”ã—ã¾ã—ãŸ")
                return None
    
    return None


if __name__ == "__main__":
    print("=" * 50)
    print("--- ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆèµ·å‹• ---")
    print("Gemini APIã‚’ä½¿ç”¨ã—ã¦æœ€æ–°ã®AIãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åé›†ã—ã¾ã™...")
    print("=" * 50)
    
    result = collect_news()
    
    if result:
        print("=" * 50)
        print(f"âœ… ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼ˆ{len(result)}ä»¶ï¼‰")
        print("=" * 50)
    else:
        print("=" * 50)
        print("âŒ ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†ã«å¤±æ•—ã—ã¾ã—ãŸ")
        print("GEMINI_API_KEYã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        print("=" * 50)
        sys.exit(1)
